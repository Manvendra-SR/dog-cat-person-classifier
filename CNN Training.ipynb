{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9954f7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5532bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip '/content/Classification_dataset_v3.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c4e69f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = '/content/Classification_dataset_v3/images/train'\n",
    "for label, class_dir in enumerate(os.listdir(image_dir)):\n",
    "  print(label, class_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a57a3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "  def __init__(self, image_dir, transform=None):\n",
    "    self.image_dir = image_dir\n",
    "    self.image_paths = []\n",
    "    self.labels = []\n",
    "    self.class_name = {}\n",
    "    self.transform = transform\n",
    "\n",
    "    for label, class_dir in enumerate(os.listdir(image_dir)):\n",
    "      self.class_name[label] = class_dir\n",
    "      class_path = os.path.join(image_dir, class_dir)\n",
    "      for img_name in os.listdir(class_path):\n",
    "        self.image_paths.append(os.path.join(class_path, img_name))\n",
    "        self.labels.append(label)\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.image_paths)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    img_path = self.image_paths[idx]\n",
    "    image = Image.open(img_path).convert(\"RGB\")\n",
    "    label = self.labels[idx]\n",
    "\n",
    "    if self.transform:\n",
    "      image = self.transform(image)\n",
    "\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a588e8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128,128)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])]\n",
    ")\n",
    "# mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85dd35ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image_dir = '/content/Classification_dataset_v3/images/train'\n",
    "test_image_dir = '/content/Classification_dataset_v3/images/test'\n",
    "\n",
    "train_image_dataset = ImageDataset(image_dir=train_image_dir, transform=transform)\n",
    "test_image_dataset = ImageDataset(image_dir=test_image_dir, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb0fedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image_loader = DataLoader(dataset=train_image_dataset, batch_size=32, shuffle=True)\n",
    "test_image_loader = DataLoader(dataset=test_image_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4045485f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for images,labels in train_image_loader:\n",
    "  print(images.shape, labels.shape)\n",
    "  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d96d256",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105c40d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_image_dataset.class_name)\n",
    "print(test_image_dataset.class_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca7bc7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for images, labels in train_image_loader:\n",
    "  print(images.shape, labels.shape)\n",
    "  img = images[0].numpy()\n",
    "  print(img.shape)\n",
    "  label = labels[0].item()\n",
    "  print(train_image_dataset.class_name[label])\n",
    "  img = np.transpose(img, (1,2,0))\n",
    "  print(img.shape)\n",
    "  print(label)\n",
    "  plt.imshow(img)\n",
    "  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d176d77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74ece10",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomCnnModel(nn.Module):\n",
    "  def __init__(self,input_dim, num_classes):\n",
    "    super(CustomCnnModel, self).__init__()\n",
    "    self.input_dim = input_dim\n",
    "    self.num_classes = num_classes\n",
    "\n",
    "    self.conv_layers = nn.Sequential(\n",
    "        # C1\n",
    "        nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1),\n",
    "        # 128x128x3 --> 3x3x3x32 --> wxhx32\n",
    "        nn.BatchNorm2d(32),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "        # C2\n",
    "        nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "        nn.BatchNorm2d(64),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "        # C3\n",
    "        nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "        nn.BatchNorm2d(128),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "        # C4\n",
    "        nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
    "        nn.BatchNorm2d(256),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "    )\n",
    "\n",
    "    self._to_linear = None\n",
    "    self._get_conv_output(self.input_dim)\n",
    "\n",
    "    self.fc_layers = nn.Sequential(\n",
    "        nn.Linear(self._to_linear, 512),\n",
    "        nn.ReLU(),\n",
    "        # nn.Dropout(0.2)\n",
    "        nn.Linear(512, 128),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(128, self.num_classes),\n",
    "    )\n",
    "\n",
    "    # 256 x 12 x 12\n",
    "\n",
    "  def _get_conv_output(self, input_dim=128):\n",
    "    with torch.no_grad():\n",
    "      dummy_input = torch.zeros(1,3, input_dim, input_dim)\n",
    "      output = self.conv_layers(dummy_input)\n",
    "      self._to_linear = output.view(1, -1).size(1)\n",
    "\n",
    "  def forward(self,x):\n",
    "    x = self.conv_layers(x)\n",
    "    x = x.view(x.size(0), -1)\n",
    "    x = self.fc_layers(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9122bdeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = CustomCnnModel(input_dim=128, num_classes=3).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb74cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(),lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9da10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "epochs = 40\n",
    "for epoch in range(epochs):\n",
    "  model.train()\n",
    "  running_loss = 0.0\n",
    "  for images, labels in train_image_loader:\n",
    "    images,labels = images.to(device), labels.to(device)\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(images)\n",
    "    # [x, 3, 128, 128]\n",
    "\n",
    "    loss = criterion(outputs, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    running_loss+=loss.item()\n",
    "  print(f\"Epoch {epoch+1}/{epochs}, Loss : {running_loss/len(train_image_loader)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc90bced",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"cnn_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3fc18b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for images, labels in test_image_loader:\n",
    "  print(labels.shape)\n",
    "  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190c4ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model\n",
    "\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "  for images, labels in test_image_loader:\n",
    "    images,labels = images.to(device), labels.to(device)\n",
    "    outputs = model(images)\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Test accuracy is :{100* correct / total:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b39612c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85630e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageClassifier:\n",
    "  def __init__(self, model_path, class_names):\n",
    "    self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    self.model = CustomCnnModel(input_dim=128, num_classes=3).to(self.device)\n",
    "    self.model.load_state_dict(torch.load(model_path, map_location=self.device))\n",
    "    self.model.eval()\n",
    "    self.class_names = class_names\n",
    "    self.transform = transforms.Compose([\n",
    "      transforms.Resize((128,128)),\n",
    "      transforms.ToTensor(),\n",
    "      transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])]\n",
    "    )\n",
    "\n",
    "  def predict(self, image_path):\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    input_tensor = self.transform(image).unsqueeze(0).to(self.device)\n",
    "    with torch.no_grad():\n",
    "      output = self.model(input_tensor)\n",
    "      _, predicted = torch.max(output, 1)\n",
    "    label = self.class_names[predicted.item()]\n",
    "\n",
    "    img = cv2.imread(image_path)\n",
    "    cv2.putText(img, label, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
    "    cv2.imwrite(\"output_image.jpg\",img)\n",
    "    return label\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d163804b",
   "metadata": {},
   "outputs": [],
   "source": [
    "classfier = ImageClassifier(\"/content/saved/cnn_model.pth\", train_image_dataset.class_name )\n",
    "label = classfier.predict(\"/content/Classification_dataset_v3/images/test/Dog/dog_1000.jpg\")\n",
    "print(f\"Predicted class is : {label}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
